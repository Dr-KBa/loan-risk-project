{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bc1e2ad",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3347f96",
   "metadata": {},
   "source": [
    "This notebook is dedicated for Neural Network (bonus challenge) training and performance evaluation. Also, general conclusions of this project are presented in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "429571f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve, classification_report, roc_auc_score\n",
    "\n",
    "%load_ext nb_black\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cee474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/drkazimieras/Turing College/Home credit default risk/df_for_Neural_net.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32455b7",
   "metadata": {},
   "source": [
    "# Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff89c1e0",
   "metadata": {},
   "source": [
    "Here is the explanation of neural network architecture as used for training (summarized by GPT).\n",
    "\n",
    "**Neural Network Architecture**\n",
    "\n",
    "- Sequential Model: Sequential() initializes a linear stack of layers in the neural network, meaning each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "- Dense Layers:Dense(128, activation='relu', input_shape=(X_train.shape[1],)): The first hidden layer with 128 neurons. The relu (Rectified Linear Unit) activation function is used, which is a common choice for hidden layers. The input_shape parameter is set to the shape of the input data.Dense(64, activation='relu'): The second hidden layer with 64 neurons, also using the relu activation function. Dense(1, activation='sigmoid'): The output layer with a single neuron. The sigmoid activation function is used, which is suitable for binary classification as it outputs a value between 0 and 1, representing the probability of belonging to the positive class.\n",
    "\n",
    "**Compilation Parameters**\n",
    "\n",
    "- Optimizer - Adam: The adam optimizer is an extension to stochastic gradient descent that has become the default optimizer for many deep learning applications. It's known for its efficiency in handling sparse gradients and adaptive learning rates.\n",
    "- Loss Function - Binary Crossentropy: The loss function for binary classification problems is binary_crossentropy. It measures the performance of a classification model whose output is a probability value between 0 and 1. Binary crossentropy loss function is ideal for binary classification models.\n",
    "- Metrics - Accuracy: The metric used to evaluate the model is accuracy, which calculates how often predictions match binary labels. It is the ratio of the number of correct predictions to the total number of predictions.\n",
    "\n",
    "**Training and Evaluation**\n",
    "\n",
    "- Training the Model - fit: The fit method trains the model for a fixed number of epochs (iterations over the entire dataset). Here, it's set to 10 epochs with a batch size of 32, meaning in each epoch, the dataset is divided into batches of 32 samples, and the network weights are updated after processing each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee13e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "df = pd.get_dummies(df, columns=categorical_cols)\n",
    "\n",
    "y = df['TARGET']  \n",
    "X = df.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=93, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ddcf048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "139916/139916 [==============================] - 96s 684us/step - loss: 0.0683 - accuracy: 0.9774\n",
      "Epoch 2/10\n",
      "139916/139916 [==============================] - 97s 690us/step - loss: 0.0294 - accuracy: 0.9904\n",
      "Epoch 3/10\n",
      "139916/139916 [==============================] - 97s 691us/step - loss: 0.0207 - accuracy: 0.9934\n",
      "Epoch 4/10\n",
      "139916/139916 [==============================] - 97s 693us/step - loss: 0.0169 - accuracy: 0.9948\n",
      "Epoch 5/10\n",
      "139916/139916 [==============================] - 97s 693us/step - loss: 0.0145 - accuracy: 0.9957\n",
      "Epoch 6/10\n",
      "139916/139916 [==============================] - 97s 695us/step - loss: 0.0126 - accuracy: 0.9963\n",
      "Epoch 7/10\n",
      "139916/139916 [==============================] - 98s 698us/step - loss: 0.0114 - accuracy: 0.9967\n",
      "Epoch 8/10\n",
      "139916/139916 [==============================] - 98s 704us/step - loss: 0.0104 - accuracy: 0.9970\n",
      "Epoch 9/10\n",
      "139916/139916 [==============================] - 98s 704us/step - loss: 0.0097 - accuracy: 0.9973\n",
      "Epoch 10/10\n",
      "139916/139916 [==============================] - 99s 706us/step - loss: 0.0090 - accuracy: 0.9975\n",
      "34979/34979 [==============================] - 14s 389us/step - loss: 0.0099 - accuracy: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00992470420897007, 0.9972733855247498]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9136d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34979/34979 [==============================] - 14s 386us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1032543\n",
      "           1       0.98      0.98      0.98     86785\n",
      "\n",
      "    accuracy                           1.00   1119328\n",
      "   macro avg       0.99      0.99      0.99   1119328\n",
      "weighted avg       1.00      1.00      1.00   1119328\n",
      "\n",
      "ROC-AUC Score: 0.999529997252514\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).ravel()\n",
    "\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred_label))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC-AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab7b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, 'NN_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000ecf95",
   "metadata": {},
   "source": [
    "## XGBoost training for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5818f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model = XGBClassifier(\n",
    "    scale_pos_weight=sum(y_train == 0) / sum(y_train == 1), eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "XGB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd338673",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(XGB_model, X_test, y_test)\n",
    "plt.title(\"ROC for XGBoost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea3469",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc27a781",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7888331",
   "metadata": {},
   "source": [
    "If additional data is available to the bank, bigger models can be created. Neural networks seems to perform beter for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ccf2b8",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982fb9b3",
   "metadata": {},
   "source": [
    "To achieve real and imaginary goals following steps were taken:\n",
    "\n",
    "1. Financial data of past clients were structured, analyzed, and and presented.\n",
    "2. Model 1 that would help bank quickly (having limited data) evaluate customers' creditworthiness was created, CatBoost model was optimized.\n",
    "3. Model was deployed to the cloud and is accessible via HTTP requests.\n",
    "4. Model is accessible via simple user interface so that bank employees can quickly evaluate weather client is worth further considerations for the loan. Model had live demo for the bank.\n",
    "5. More complex model (Model 2) that may be used after initial filtering (Model 1), or instead of it was created and evaluated.\n",
    "\n",
    "Possible improvements:\n",
    "\n",
    "1. Explore all the features included in the datasets.\n",
    "2. Improve the model pipelines to be able to accept new data and retrain.\n",
    "3. Create a fully functional website to access Model 1.\n",
    "4. Notebook code could be converted to python files for the more versatile and professional use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88879f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
